{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing SAE Activations for Perfect vs Non-Perfect Matches\n",
    "\n",
    "This notebook analyzes the layer 2 SAE activations from Llama 3.1 8B for perfect matches vs non-perfect matches in the memorization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model using TransformerLens\n",
    "model = HookedTransformer.from_pretrained(\"meta-llama/Llama-3.1-8B\", device=device, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# No need for separate tokenizer as it's included in the HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the SAE\n",
    "# LAYER_NUMBER = 7\n",
    "# release = \"llama_scope_lxr_8x\"\n",
    "# sae_id = f\"l{LAYER_NUMBER}r_8x\"\n",
    "# sae = SAE.from_pretrained(release, sae_id)[0]\n",
    "# sae = sae.to(device)\n",
    "\n",
    "# Load the SAEs for all layers\n",
    "sae_layers = range(0, 4)\n",
    "release = \"llama_scope_lxr_8x\"\n",
    "saes = []\n",
    "print(\"Loading SAEs for all layers...\")\n",
    "for layer in tqdm(sae_layers):\n",
    "    sae_id = f\"l{layer}r_8x\"\n",
    "    sae = SAE.from_pretrained(release, sae_id)[0]\n",
    "    sae = sae.to(device)\n",
    "    saes.append(sae)\n",
    "print(\"Finished loading SAEs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('memorization_results_L50_O50.csv')\n",
    "\n",
    "# Split into perfect and non-perfect matches\n",
    "perfect_matches = df[df['perfect_match'] == True]\n",
    "non_perfect_matches = df[(df['perfect_match'] == False) & (df['matching_tokens'] == 0)]\n",
    "\n",
    "# Sample from each\n",
    "num_samples = 20\n",
    "random.seed(42)  # For reproducibility\n",
    "perfect_sample = perfect_matches.sample(n=num_samples)\n",
    "non_perfect_sample = non_perfect_matches.sample(n=num_samples)\n",
    "\n",
    "print(f\"Total perfect matches: {len(perfect_matches)}\")\n",
    "print(f\"Total non-perfect matches: {len(non_perfect_matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(text_input, text_output):\n",
    "    \"\"\"Get SAE activations for a given input-output pair using TransformerLens\"\"\"\n",
    "    # Concatenate input and output\n",
    "    full_text = text_input + text_output\n",
    "    \n",
    "    # Tokenize and get model activations using run_with_cache\n",
    "    tokens = model.to_tokens(full_text, prepend_bos=False)\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    # Get layer activations for all layers\n",
    "    all_layer_acts = {}\n",
    "    for layer, sae in zip(sae_layers, saes):\n",
    "        # Get layer activations\n",
    "        layer_acts = cache['resid_pre', layer]\n",
    "        \n",
    "        # Get SAE activations\n",
    "        sae_acts = sae.encode(layer_acts)\n",
    "        \n",
    "        # Only keep activations for output tokens (last 50)\n",
    "        output_acts = sae_acts[:, -50:, :]\n",
    "        \n",
    "        all_layer_acts[layer] = output_acts.squeeze(0)  # Remove batch dimension\n",
    "        \n",
    "    return all_layer_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations for perfect matches\n",
    "perfect_activations_by_layer = {layer: [] for layer in sae_layers}\n",
    "print(\"Processing perfect matches...\")\n",
    "for _, row in tqdm(perfect_sample.iterrows()):\n",
    "    acts_dict = get_activations(row['input_text'], row['generated_continuation_text'])\n",
    "    for layer in sae_layers:\n",
    "        perfect_activations_by_layer[layer].append(acts_dict[layer])\n",
    "\n",
    "# Get activations for non-perfect matches\n",
    "non_perfect_activations_by_layer = {layer: [] for layer in sae_layers}\n",
    "print(\"\\nProcessing non-perfect matches...\")\n",
    "for _, row in tqdm(non_perfect_sample.iterrows()):\n",
    "    acts_dict = get_activations(row['input_text'], row['generated_continuation_text'])\n",
    "    for layer in sae_layers:\n",
    "        non_perfect_activations_by_layer[layer].append(acts_dict[layer])\n",
    "\n",
    "# Stack all activations for each layer\n",
    "perfect_acts_stacked = {\n",
    "    layer: torch.stack(acts, dim=0) \n",
    "    for layer, acts in perfect_activations_by_layer.items()\n",
    "}\n",
    "non_perfect_acts_stacked = {\n",
    "    layer: torch.stack(acts, dim=0)\n",
    "    for layer, acts in non_perfect_activations_by_layer.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate statistics\n",
    "# def compute_stats(activations):\n",
    "#     \"\"\"Compute various statistics for the activations\"\"\"\n",
    "#     # L0 (number of active features)\n",
    "#     l0 = (activations > 0).float().sum(-1).mean().item()\n",
    "    \n",
    "#     # Mean activation when active\n",
    "#     mean_active = activations[activations > 0].mean().item()\n",
    "    \n",
    "#     # Max activation\n",
    "#     max_act = activations.max().item()\n",
    "    \n",
    "#     # Feature sparsity (fraction of features that never activate)\n",
    "#     feature_sparsity = ((activations > 0).sum(0) == 0).float().mean().item()\n",
    "    \n",
    "#     return {\n",
    "#         'L0 (avg active features)': l0,\n",
    "#         'Mean activation when active': mean_active,\n",
    "#         'Max activation': max_act,\n",
    "#         'Feature sparsity': feature_sparsity\n",
    "#     }\n",
    "\n",
    "# perfect_stats = compute_stats(perfect_acts_stacked)\n",
    "# non_perfect_stats = compute_stats(non_perfect_acts_stacked)\n",
    "\n",
    "# # Print statistics\n",
    "# print(\"Statistics for perfect matches:\")\n",
    "# for k, v in perfect_stats.items():\n",
    "#     print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# print(\"\\nStatistics for non-perfect matches:\")\n",
    "# for k, v in non_perfect_stats.items():\n",
    "#     print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot L0 histograms\n",
    "# l0_perfect = (perfect_acts_stacked > 0).float().sum(-1).cpu().numpy()\n",
    "# l0_non_perfect = (non_perfect_acts_stacked > 0).float().sum(-1).cpu().numpy()\n",
    "\n",
    "# # Create a DataFrame for plotting\n",
    "# l0_data = pd.DataFrame({\n",
    "#     'L0': np.concatenate([l0_perfect, l0_non_perfect]),\n",
    "#     'Type': ['Perfect Match'] * len(l0_perfect) + ['Non-Perfect Match'] * len(l0_non_perfect)\n",
    "# })\n",
    "\n",
    "# # Plot histogram\n",
    "# fig = px.histogram(l0_data, x='L0', color='Type', barmode='overlay',\n",
    "#                   title='Distribution of Active Features (L0)',\n",
    "#                   labels={'L0': 'Number of Active Features', 'count': 'Frequency'})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot activation magnitude distributions\n",
    "# act_perfect = perfect_acts_stacked[perfect_acts_stacked > 0].float().detach().cpu().numpy()\n",
    "# act_non_perfect = non_perfect_acts_stacked[non_perfect_acts_stacked > 0].float().detach().cpu().numpy()\n",
    "\n",
    "# # Create a DataFrame for plotting\n",
    "# act_data = pd.DataFrame({\n",
    "#     'Activation': np.concatenate([act_perfect, act_non_perfect]),\n",
    "#     'Type': ['Perfect Match'] * len(act_perfect) + ['Non-Perfect Match'] * len(act_non_perfect)\n",
    "# })\n",
    "\n",
    "# # Plot histogram\n",
    "# fig = px.histogram(act_data, x='Activation', color='Type', barmode='overlay',\n",
    "#                   title='Distribution of Activation Magnitudes',\n",
    "#                   labels={'Activation': 'Activation Value', 'count': 'Frequency'})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_features = 10\n",
    "\n",
    "# Analyze feature usage patterns\n",
    "def get_top_features(activations, n=num_top_features):\n",
    "    \"\"\"Get the most frequently activated features\"\"\"\n",
    "    # Compress activations across all samples first\n",
    "    compressed_acts = activations.reshape(-1, activations.shape[-1])\n",
    "    feature_counts = (compressed_acts > 0).float().sum(0)\n",
    "    top_features = torch.topk(feature_counts, n)\n",
    "    return top_features.indices.cpu().numpy(), top_features.values.cpu().numpy()\n",
    "\n",
    "# Since we're working with a dict now, we need to handle one layer at a time\n",
    "for layer in sae_layers:\n",
    "    print(f\"\\nAnalyzing layer {layer}:\")\n",
    "    \n",
    "    # Get the activation tensors for this layer\n",
    "    perfect_acts = perfect_acts_stacked[layer]\n",
    "    non_perfect_acts = non_perfect_acts_stacked[layer]\n",
    "\n",
    "    # Get top features for both types\n",
    "    perfect_top_idx, perfect_top_counts = get_top_features(perfect_acts)\n",
    "    non_perfect_top_idx, non_perfect_top_counts = get_top_features(non_perfect_acts)\n",
    "\n",
    "    # Create a set of all features that were activated in either type\n",
    "    overlap_features = set(perfect_top_idx.tolist()) | set(non_perfect_top_idx.tolist())\n",
    "\n",
    "    # For each feature, see how many times it was activated in each type\n",
    "    perfect_acts_flat = perfect_acts.reshape(-1, perfect_acts.shape[-1])\n",
    "    non_perfect_acts_flat = non_perfect_acts.reshape(-1, non_perfect_acts.shape[-1])\n",
    "    \n",
    "    feature_counts = (perfect_acts_flat > 0).float().sum(0).int().cpu().numpy()\n",
    "    feature_counts_non_perfect = (non_perfect_acts_flat > 0).float().sum(0).int().cpu().numpy()\n",
    "    \n",
    "    # Create a table to show all the features (even some that we only activated by one type)\n",
    "    feature_counts_table = pd.DataFrame({\n",
    "        'Feature': list(overlap_features),\n",
    "        'Perfect': feature_counts[list(overlap_features)],\n",
    "        'Non-Perfect': feature_counts_non_perfect[list(overlap_features)]\n",
    "    })\n",
    "\n",
    "    # Sort the table by the number of activations in each type\n",
    "    feature_counts_table = feature_counts_table.sort_values(by=['Perfect', 'Non-Perfect'], ascending=False)\n",
    "\n",
    "    # Print the table\n",
    "    print(feature_counts_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What I Care About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all features that were activated in either type\n",
    "overlap_features = set(perfect_top_idx) | set(non_perfect_top_idx)\n",
    "\n",
    "# For each feature, see how many times it was activated in each type\n",
    "feature_counts = (perfect_acts_stacked > 0).float().sum((0)).int().cpu().numpy()\n",
    "feature_counts_non_perfect = (non_perfect_acts_stacked > 0).float().sum((0)).int().cpu().numpy()\n",
    "\n",
    "# Create a table to show all the features (even some that we only activated by one type)\n",
    "feature_counts_table = pd.DataFrame({\n",
    "    'Feature': list(overlap_features),\n",
    "    'Perfect': feature_counts[list(overlap_features)],\n",
    "    'Non-Perfect': feature_counts_non_perfect[list(overlap_features)]\n",
    "})\n",
    "\n",
    "# Sort the table by the number of activations in each type\n",
    "feature_counts_table = feature_counts_table.sort_values(by=['Perfect', 'Non-Perfect'], ascending=False)\n",
    "\n",
    "# Print the table\n",
    "print(feature_counts_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
